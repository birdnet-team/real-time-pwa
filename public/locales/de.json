{
  "app_title": "BirdNET Live",
  "nav_live": "Live",
  "nav_explore": "Entdecken",
  "nav_about": "Über",
  "nav_share": "Teilen",
  "status_init": "Tippe auf 'Start' zur Aufnahme",
  "status_loading": "Lade BirdNET…",
  "status_loading_percent": "Lade BirdNET… {0}%",
  "status_listening_inference": "Nehme auf… (Inferenz dauerte {0} ms)",
  "status_worker_error": "BirdNET-Fehler. Seite neu laden.",
  "status_ready": "Modell bereit. Tippe auf 'Start'.",
  "status_requesting_mic": "Frage Mikrofonzugriff an…",
  "status_listening": "Nehme auf…",
  "status_mic_failed": "Mikrofonzugriff fehlgeschlagen.",
  "status_stopped": "Gestoppt. Tippe auf 'Start'.",
  "status_browser_old": "Browser zu alt. Bitte aktualisieren.",
  "status_audio_failed": "Audio-Fehler. Bitte neu laden.",
  "status_reloading_model": "Lade Modell neu…",
  "btn_start": "Start",
  "btn_stop": "Stopp",
  "settings_title": "Einstellungen",
  "sec_detection": "Detektionen & Modell",
  "lbl_use_geo": "Standort verwenden",
  "lbl_coordinates": "Koordinaten",
  "status_geo_waiting": "Warte auf Standort…",
  "status_geo_disabled": "Standort deaktiviert.",
  "status_geo_requesting": "Frage Standort ab…",
  "status_geo_acquired": "Standort gefunden.",
  "status_geo_failed": "Standort fehlgeschlagen.",
  "status_geo_unsupported": "Standort nicht unterstützt.",
  "lbl_ui_lang": "App Sprache",
  "lbl_label_lang": "Label Sprache",
  "lbl_threshold": "Schwellenwert",
  "lbl_sensitivity": "Empfindlichkeit",  
  "lbl_inference_interval": "Inferenz-Intervall",  
  "lbl_mic_gain": "Mikrofon-Verstärkung",
  "lbl_rumble_filter": "Geräuschfilter (Hoch-Pass)",
  "msg_rumble_hint": "Entfernt Wind- und Verkehrsgeräusche unterhalb dieser Frequenz.",
  "sec_spectrogram": "Spektrogramm",
  "lbl_duration": "Dauer",
  "lbl_colormap": "Farbschema",
  "lbl_freq_range": "Frequenzbereich (Hz)",
  "lbl_min": "Min",
  "lbl_max": "Max",
  "lbl_grid_lines": "Gitterlinien",
  "lbl_amp_range": "Amplitudenbereich (dB)",
  "lbl_min_floor": "Min",
  "lbl_max_ceiling": "Max",
  "btn_close": "Schließen",
  "msg_no_detections": "Keine Detektionen über {0}% Wahrscheinlichkeit.",
  "msg_detections_placeholder": "Detektionen erscheinen hier.",
  "msg_geo_active": "Standortfilter aktiv.",
  "msg_explore_title": "Lokale Arten entdecken",
  "msg_explore_geo_disabled": "Aktiviere den Standort in den Einstellungen, um lokale Arten zu sehen.",
  "msg_explore_no_species": "Keine Arten mit Wahrscheinlichkeit ≥ {0}% gefunden.",
  "msg_explore_lower_threshold": "Versuche den Schwellenwert zu senken.",
  "lbl_geo_score": "Standort-Score: {0}%",
  "sec_geomodel": "Geomodell",
  "lbl_occurrence_threshold": "Vorkommens-Wahrscheinlichkeit",
  "msg_occurrence_hint_pre": "Zeige Arten mit ≥ ",
  "msg_occurrence_hint_post": " Wahrscheinlichkeit",
  "about_title": "Über BirdNET Live",
  "about_subtitle": "Echtzeit-Vogelstimmenidentifikation direkt in deinem Webbrowser.",
  "about_demo_title": "Was ist diese Demo?",
  "about_demo_p1": "<strong>BirdNET Live</strong> ist eine experimentelle Progressive Web App (PWA), die zeigt, wie moderne Webbrowser anspruchsvolle Machine-Learning-Modelle ausführen können. Im Gegensatz zur offiziellen BirdNET-App, die nativ auf Android/iOS läuft, läuft diese Version in Chrome, Safari oder Firefox mit <strong>TensorFlow.js</strong>.",
  "about_demo_p2": "Das bedeutet, du kannst Vögel auf deinem Laptop, Tablet oder Telefon identifizieren, ohne eine App aus dem Store zu installieren, und – was entscheidend ist – <strong>ohne Audiodaten an einen Server zu senden</strong>.",
  "about_birdnet_title": "Was ist BirdNET?",
  "about_birdnet_p1": "BirdNET ist eine Forschungsplattform, die gemeinsam vom <strong>K. Lisa Yang Center for Conservation Bioacoustics</strong> am Cornell Lab of Ornithology und der <strong>Technischen Universität Chemnitz</strong> entwickelt wurde.",
  "about_birdnet_p2": "Das Projekt nutzt künstliche neuronale Netze, um Computer darauf zu trainieren, mehr als 6.000 der häufigsten Vogelarten weltweit zu identifizieren. Es ist eines der fortschrittlichsten Werkzeuge für das akustische Monitoring von Vögeln.",
  "about_btn_official": "Offizielle BirdNET-Website besuchen",
  "about_how_title": "Wie die Erkennung funktioniert",
  "about_step1_title": "Audioaufnahme",
  "about_step1_desc": "Die Web Audio API deines Browsers nimmt den Ton von deinem Mikrofon auf und re-sampelt ihn auf 48.000 Hz.",
  "about_step2_title": "Spektrogramm-Erzeugung",
  "about_step2_desc": "Das Audio wird in 3-Sekunden-Abschnitte unterteilt. Diese Abschnitte werden in <strong>Mel-Spektrogramme</strong> umgewandelt – visuelle Darstellungen von Schall, die die Frequenzintensität über die Zeit zeigen.",
  "about_step3_title": "Neuronale Netz-Inferenz",
  "about_step3_desc": "Das Spektrogramm-Bild wird in ein Convolutional Neural Network (CNN) eingespeist. Dieses Modell hat gelernt, Vogelrufe in diesen Bildern zu „sehen“ und sie von Lärm und anderen Tieren zu unterscheiden.",
  "about_step4_title": "Nachbearbeitung",
  "about_step4_desc": "Das Modell gibt Wahrscheinlichkeitswerte für Tausende von Arten aus. Wir wenden einen <strong>Konfidenzschwellenwert</strong> (z. B. 25 %) und optional einen <strong>Standortfilter</strong> an, um Vögel auszublenden, die in deiner Gegend unwahrscheinlich sind.",
  "about_contact_title": "Kontakt",
  "about_contact_desc": "Fragen zu BirdNET-Forschung, Tools oder Kooperationen:",
  "about_privacy_link": "Datenschutzerklärung & Impressum",
  "about_github_title": "BirdNET Live auf GitHub",
  "about_github_desc": "Der Quellcode für BirdNET Live ist auf GitHub verfügbar. Du kannst den Code inspizieren, Probleme melden oder Verbesserungen beitragen.",
  "about_btn_repo": "Repository ansehen",
  "share_title": "BirdNET Live teilen",
  "share_desc": "Scanne diesen Code, um die App auf einem anderen Gerät zu öffnen.",
  "share_btn_link": "Link teilen",
  "share_msg_text": "Schau dir diese Echtzeit-Vogel-ID-App an!"
}